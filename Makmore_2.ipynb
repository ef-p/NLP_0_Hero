{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Our last method of taking the counts of each bigram won't scale at all. It will grow exponentionally. We're going to take an MLP approach"
      ],
      "metadata": {
        "id": "vCOZn94a6nfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be following the approach of this 2003 paper: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf.\n",
        "\n",
        "While this paper used a word level model, we'll be sticking to character level models, but with the same modeling approach.\n",
        "\n",
        "The paper took a vocabulary of 17,000 words and associated a 30 element feature vector to each, embedding them in a 30 dimensional space. The idea is that words that have similar meanings may end up near eachother in this 30D space, and conversly words that are very different, should be very far from each other. (Note: the paper mentions feature size numbers of 30, 60 and 100 in their experiments).\n",
        "\n",
        "The great power here is the ability to use 'closeness' within the embedding space to generalize broadly.\n",
        "\n"
      ],
      "metadata": {
        "id": "o_sgAMBG7KUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ef-p/NLP_0_Hero.git\n",
        "%cd /content/NLP_0_Hero"
      ],
      "metadata": {
        "id": "hbtUL-kYmcT0",
        "outputId": "b8ad6e03-075d-4891-c2d8-4834b888a83c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_0_Hero'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 14 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18/18), 948.09 KiB | 9.12 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/NLP_0_Hero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "-PonkQP67JLU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the words\n",
        "\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vunbv2uIBe2k",
        "outputId": "1db69a46-174b-42fa-8cea-75d411933697"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV8DpAr3Gkru",
        "outputId": "dabbc634-dd3b-46da-cf38-f168369d114c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the \"vocabulary\" of characters and the mapping to and from integers\n",
        "\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0 # string to int\n",
        "itos = {i:s for s, i in stoi.items()} # int to string\n",
        "print(stoi,'\\n',itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCZcghYHGpTl",
        "outputId": "3944dbdf-667b-48ae-b5ba-098e2bdeb378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0} \n",
            " {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's how we build the dataset\n",
        "# this is the context length of how far back we're going to look to predict the next char.\n",
        "block_size = 3 # here we're looking at the last 3 characters to guess the 4th.\n",
        "\n",
        "X,Y = [], []\n",
        "# just the first five words for now .\n",
        "for w in words[:5]:\n",
        "  #print(w)\n",
        "  context = [0]*block_size # creates a list the size of block_size,\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch] #what's the indx of the character ?\n",
        "    X.append(context) # add the context, first list should be all '.'\n",
        "    Y.append(ix) # the index to get the character from itos.\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    #the above prints the current context, --> and then the next letter\n",
        "\n",
        "    context = context[1:] + [ix] # crop, and append the index for the next character.\n",
        "\n",
        "X,Y = torch.tensor(X), torch.tensor(Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKt54n-aG04D",
        "outputId": "05744e76-2aff-4e41-f510-fad2749b6a69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yi40FlfJ-d5",
        "outputId": "ea7b0280-4daa-424d-92f4-6ffc5c5a9c31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As you can see above we have 32 training examples that we made out of our first five names. Each of these examples is a triplet of charcters, made from our 27 possible characters. These are the triplets that appear when considering only the first five names, as we eventually use the entire dataset, we'll get more**"
      ],
      "metadata": {
        "id": "ZYB2mFiJN3Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# here's our look up table.\n",
        "# the paper takes its 17000 words and puts them in spaces as small as 30\n",
        "# we'll start with a 2D space\n",
        "# 27 rows for our characters, and two columns for the size of the feature space\n",
        "C = torch.randn((27,2))"
      ],
      "metadata": {
        "id": "InazqVbZNtF9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's one embedding\n",
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzgfVOnvPWz6",
        "outputId": "cfc1fb00-6c86-4d37-9946-b30cb69818ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0853,  0.0642])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#index using lists\n",
        "\n",
        "C[[5,6,7]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP4WXy-3SX8M",
        "outputId": "5564a184-4db0-4c05-c2a2-1099f913e9c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0853,  0.0642],\n",
              "        [-1.3417,  0.4200],\n",
              "        [-1.3186,  0.4074]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can feed it a  tensor\n",
        "C[torch.tensor([5,6,7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3hAYR8ETUen",
        "outputId": "f58fdece-81cf-41d8-f314-1861c590a0e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0853,  0.0642],\n",
              "        [-1.3417,  0.4200],\n",
              "        [-1.3186,  0.4074]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can even send the same index again and again\n",
        "C[torch.tensor([5,6,7,7,7,7,7,7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XankGhqTX3W",
        "outputId": "bd76ffcd-f9dc-44bc-f178-9c8fc4da6130"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0853,  0.0642],\n",
              "        [-1.3417,  0.4200],\n",
              "        [-1.3186,  0.4074],\n",
              "        [-1.3186,  0.4074],\n",
              "        [-1.3186,  0.4074],\n",
              "        [-1.3186,  0.4074],\n",
              "        [-1.3186,  0.4074],\n",
              "        [-1.3186,  0.4074]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X].shape # we can therefore embed all the ints in X with just C[X]\n",
        "# lets look at the shape to get this right in our heads."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3-lLIMcTb89",
        "outputId": "42535b1b-ec6d-4a52-ba25-0e0f90e90a63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have 32 entries, each 3 characters long (our context length). and now each of the characters is identified by a 2D vector embedding. Let's just prove this to our selves before moving on."
      ],
      "metadata": {
        "id": "6xu0c77VV8G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[13,2] # lets pluck out a random int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddcJN4KlTu_9",
        "outputId": "f84d2f9a-6fb3-4b97-f7aa-46ecc539d13d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X][13,2] # if we've done this correctly we should get the embedding for that int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw4a-GvVUOoM",
        "outputId": "5423776c-f817-4ca7-ac01-f38fe8ab1e8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5659, -0.4650])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, these number values are really characters. So, to reiterate, if we've got everything straight here the embedding for X[32,2] aka the embedding for tensor(1), should be [0.5771, 0.3914]. So if we've done this right we would expect C[X][13,2] == C[1], the previously mentioned embedding."
      ],
      "metadata": {
        "id": "tZPctZCKUjF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[1] #the value is the same! pytorch indexing is very handy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d3RDqzvUYmY",
        "outputId": "076cb438-116b-4263-eb3c-5c5784068326"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5659, -0.4650])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " emb = C[X]"
      ],
      "metadata": {
        "id": "hGXPrhT_VlhS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets make the hidden layer\n",
        "\n",
        "\n",
        "W1 = torch.randn((6, 100)) # we have 2D embeddings, and we have 3 of them, hence the 6. # the number of neurons is up to us.\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "TVetD2PrWcuO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, ideally we'd like to do the following matmul: `emb @ W1 + b1`. But these matrix dims don't work. We'll have to fix this so our tensors are the same rank.lets try anad make emb a `[32,6]` matrix."
      ],
      "metadata": {
        "id": "qN8qNxJtW6I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The 1 index (value of 3) in emb refers to our context length, the triplet of words we collceted\n",
        "#we're going to use torch.cat to smush all these into vectors with 6 elements\n",
        "#recall that each emebedding is a vector of size 2.\n",
        "conemb1 = torch.cat([emb[:,0, :], emb[:,1, :], emb[:,2, :]])\n"
      ],
      "metadata": {
        "id": "AP82YtCuXPgL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this works fine, but this isn't generalizable unfortunatly, if we had a different context length, this won't work. Lets use unbind and use it on the 1st dimension, and it'll work no matter what context length we choose."
      ],
      "metadata": {
        "id": "5vUYIrKiNpeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conemb2 = torch.cat(torch.unbind(emb,1),1)"
      ],
      "metadata": {
        "id": "RdCXXmwQN7hy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is okay, but we have an even more efficient solution.\n",
        "\n",
        "the view function works more efficiently because it doesn't involve moving anything around in memory. The storage stays exactly the same (one big vector) but some internal attributes of the object will change so that it is 'interpreted' or 'viewed' differently when we use it.\n",
        "\n",
        " So these interal structures are making it so our vector is 'interpreted' as 32,3,2 , view can change this so it's 'viewed' as 32,6. As long as everything multiplies out to be the same, we're golden."
      ],
      "metadata": {
        "id": "mpt1_bVkOBy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6).shape"
      ],
      "metadata": {
        "id": "NDLwZ6bSOJ6u",
        "outputId": "8b252a72-1077-40af-bc37-a2ac07a8cf19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we can do our operation!\n",
        "# The -1 asks pytorch to figure out what that dimension is\n",
        "# if the second dimension is 6, it can see that well this other one must be 32, otherwise the vector length would be wrong.\n",
        "\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # passing our operation through a tanh activation fun\n",
        "h.shape\n"
      ],
      "metadata": {
        "id": "LVvuzqR9PmiR",
        "outputId": "d0778f3e-e19b-4760-cbd4-00274eed84f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second set of W and B\n",
        "\n",
        "W2 = torch.randn(100,27)\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "logits = h @ W2 + b2\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "Rlil3xekQrcx",
        "outputId": "18a27d6f-16e0-469e-dd7e-398bbeccfba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdim=True) # normalize, now they're probs so every row sums to 1\n",
        "prob.shape"
      ],
      "metadata": {
        "id": "uE8eyRNDRJPP",
        "outputId": "5f3e79e4-f01c-44e5-8656-af49b58f17ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #lets get the average negative log loss\n",
        " loss = -prob[torch.arange(32), Y].log().mean()\n",
        " loss"
      ],
      "metadata": {
        "id": "otgn96fpRY3m",
        "outputId": "0b64967c-24eb-4541-ab28-94700e59d0d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.1312)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to use nn.functional's cross entropy function moving forward. Our old method was really inefficient under the hood and could in some cases behave poorly numerically speaking. If a logit is too large, it'll grow exponentially out of the range of our floating point numbers. Pytorch takes care of this under the hood by subtracting each logit by the highest value, so that our largest logit will only ever be 0.\n"
      ],
      "metadata": {
        "id": "BT0SD7DEYdv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "id": "2X9xC3yDWFX4",
        "outputId": "9c764de8-4429-4930-a9f7-f53dc147ae58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.1312)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together"
      ],
      "metadata": {
        "id": "rH7n_ze-WQ0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator=g) # each character will have a 2D embedding\n",
        "W1= torch.randn((6, 100), generator=g) # 3 triplets of 2 = 6, the 6 elm vectors are fed through 100 neurons\n",
        "b1 = torch.randn(100, generator=g) # one bias for every neuron\n",
        "W2 = torch.randn((100,27), generator=g) # Second set of weights, giving us our logits for the 27 characters, for each entry(triplet)\n",
        "b2 = torch.randn(27, generator=g) # bias for each of the last neurons\n",
        "parameters= [C, W1, b1, W2, b2]\n"
      ],
      "metadata": {
        "id": "sERI74f6EAxQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # how many parameters do we have total ?\n"
      ],
      "metadata": {
        "id": "l_2xfLdnFaxq",
        "outputId": "9fd79da4-668f-45b1-b8ce-4c4cdb0e841e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad_(True) #don't forget! We need this to train"
      ],
      "metadata": {
        "id": "bBbuWvj4FOAQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for __ in range(1000):\n",
        "  #forward pass\n",
        "  emb = C[X] # C is (27,2), X is (32,3) ---> emb is (32,3,2)\n",
        "  h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32,6)\n",
        "  logits = h @ W2 + b2 # (32,27) Second layer\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  #print(loss.item())\n",
        "\n",
        "  #backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None # zero out so we don't accumulate past gradients\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad # learning rate for us to choose.\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "8BDsH5coFVaS",
        "outputId": "17ae1ed2-2496-4851-efb8-05f8ca0be4bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25609633326530457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got our We have alot of parameters and not many examples so it's easy to overfit. We dont get to 0 exactly ( the [000] triplet can up to 4 different next labels in our dataset, so it'll still get some wrong)"
      ],
      "metadata": {
        "id": "RRDrow58HhKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run it again with the whole dataset:\n",
        "\n"
      ],
      "metadata": {
        "id": "eDt8MVQ7IYPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3 # here we're looking at the last 3 characters to guess the 4th.\n",
        "\n",
        "X,Y = [], []\n",
        "# just the first five words for now .\n",
        "for w in words:\n",
        "  #print(w)\n",
        "  context = [0]*block_size # creates a list the size of block_size,\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch] #what's the indx of the character ?\n",
        "    X.append(context) # add the context, first list should be all '.'\n",
        "    Y.append(ix) # the index to get the character from itos.\n",
        "    #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    #the above prints the current context, --> and then the next letter\n",
        "\n",
        "    context = context[1:] + [ix] # crop, and append the index for the next character.\n",
        "\n",
        "X,Y = torch.tensor(X), torch.tensor(Y)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ttxe3T-vIu41"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator=g) # each character will have a 2D embedding\n",
        "W1= torch.randn((6, 100), generator=g) # 3 triplets of 2 = 6, the 6 elm vectors are fed through 100 neurons\n",
        "b1 = torch.randn(100, generator=g) # one bias for every neuron\n",
        "W2 = torch.randn((100,27), generator=g) # Second set of weights, giving us our logits for the 27 characters, for each entry(triplet)\n",
        "b2 = torch.randn(27, generator=g) # bias for each of the last neurons\n",
        "parameters= [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad_(True) #don't forget! We need this to train"
      ],
      "metadata": {
        "id": "zplpKec5I6zD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for __ in range(10):\n",
        "  #forward pass\n",
        "  emb = C[X] # C is (27,2), X is (32,3) ---> emb is (32,3,2)\n",
        "  h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32,6)\n",
        "  logits = h @ W2 + b2 # (32,27) Second layer\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  #print(loss.item())\n",
        "\n",
        "  #backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None # zero out so we don't accumulate past gradients\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad # learning rate for us to choose.\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "V-6GpvlvJZKN",
        "outputId": "9c97404e-37f5-4137-fd5d-4219ecf46fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.051856994628906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minibatching and the learning rate\n",
        "\n",
        "The idea behind minibatching is that taking a step every epoch really slows everything down. Instead of going through the whole training set to get the ideal gradient, we can break it up into batches, and take multiple steps within one epoch. We trade quality of the gradient, for quantity and we can get to the same(or a very similar) place much faster. Careful not to have too small a batch size, there's a point where all your little steps will start to introduce noise\n",
        "\n",
        "The learning rate is a hyperparameter we can play with. too small a value and you might not traing quickly enough, too high a value can cause the learning to become unstable.\n",
        "\n",
        "reset the code above as needed to run the training loop"
      ],
      "metadata": {
        "id": "QL_gypF4Jfzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, 0 , 1000) # we'll take a list of learning rates to go through\n",
        "lrs =lrs = 10**lre"
      ],
      "metadata": {
        "id": "G78yrtCjMdbP"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lri = []\n",
        "lossi = [] #we'll track the stats for the rates\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "\n",
        "  #minbatch construcct\n",
        "  ix = torch.randint(0, X.shape[0], (32,))\n",
        "\n",
        "\n",
        "  #forward pass\n",
        "  emb = C[X[ix]] # batches of 32 at a time for each step\n",
        "  h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32,6)\n",
        "  logits = h @ W2 + b2 # (32,27) Second layer\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "  #print(loss.item())\n",
        "\n",
        "  #backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None # zero out so we don't accumulate past gradients\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  lr = lrs[i] # lets go through our different lrs\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad # learning rate for us to choose.\n",
        "\n",
        "  # track stats\n",
        "  lri.append(lre[i]) # exponent of the learning rate\n",
        "  lossi.append(loss.item())\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "GIjgFMKVKQFr",
        "outputId": "4796ce96-4751-4c43-9adb-877aae3ba252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.414894104003906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lri, lossi)"
      ],
      "metadata": {
        "id": "t2lylpeLKm1i",
        "outputId": "1e44f27a-3b97-4d59-9ad1-079850fab5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a97d2cdb970>]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our X axis is the exp of our learning rate. It looks like after $10^{-1}$ things get unstable. so a learning rate of 0.1 is probably our ideal learning rate."
      ],
      "metadata": {
        "id": "LGQ3UxC-Nhjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can retrain using $10^{-1}$ and consider decay the learning rate at the later stages of training"
      ],
      "metadata": {
        "id": "ZTNNaM7iOh6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should split our dataset into training, validation and test splits. Our model won't be very useful if it just memorizes verbatum that data it's seen.\n",
        "\n",
        "\n",
        "\n",
        "*   Training Split ~ 80% of data: to train our network\n",
        "*   Validation Split ~ 10 % of data: tune your hyperparameters\n",
        "*   Test Split ~ 10% of data: evaluate the whole model\n",
        "\n",
        "Always be precious about using the test split. It defeats the purpose if we over train on the test split.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LVa5kcmHOyp7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDve0H7OPne7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}